import ChatGPT


def initialize_llm_model(model_name='gpt-chat', api_token=None):
    """
    Initializes the LLM model with LangChain.

    :param model_name: The name of the model to use ('gpt-chat' by default).
    :param api_token: The API token for authentication (optional).
    :return: An instance of the ChatGPT model.
    """
    return ChatGPT(model_name=model_name, api_token=api_token)


def llm_interaction(query: str, llm: ChatGPT) -> str:
    """
    Interacts with the LLM to generate a response based on the given query.

    :param query: The query to send to the LLM.
    :param llm: An instance of the ChatGPT model.
    :return: The response generated by the LLM.
    """
    response = llm.generate_response(query)
    return response


# Example usage
if __name__ == "__main__":
    # Initialize the LLM model
    llm = initialize_llm_model(
        api_token="YOUR_API_TOKEN_HERE")  # Replace YOUR_API_TOKEN_HERE with your actual API token

    # Simulate a query
    query = "What are the top 5 features of the latest smartphone?"

    # Get a response from the LLM
    response = llm_interaction(query, llm)

    # Print the response
    print(response)
