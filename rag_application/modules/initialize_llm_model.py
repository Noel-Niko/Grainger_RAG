# import os
# import logging
# from typing import Optional
# from ChatGPT import ChatGPT
#
# # Setup basic configuration for logging
# logging.basicConfig(level=logging.INFO)
# logger = logging.getLogger(__name__)
#
#
# def initialize_llm_model(model_name: str = 'gpt-chat', api_token: Optional[str] = None) -> ChatGPT:
#     """
#     Initializes the LLM model with LangChain.
#
#     :param model_name: The name of the model to use ('gpt-chat' by default).
#     :param api_token: The API token for authentication (optional).
#     :return: An instance of the ChatGPT model.
#     """
#     if not api_token:
#         logger.error("API token is required for initializing the LLM model.")
#         raise ValueError("API token is required.")
#
#     return ChatGPT(model_name=model_name, api_token=api_token)
#
#
# def llm_interaction(query: str, llm: ChatGPT) -> str:
#     """
#     Interacts with the LLM to generate a response based on the given query.
#
#     :param query: The query to send to the LLM.
#     :param llm: An instance of the ChatGPT model.
#     :return: The response generated by the LLM.
#     """
#     try:
#         response = llm.generate_response(query)
#         logger.info(f"Received response: {response[:50]}...")  # Log the start of the response for brevity
#         return response
#     except Exception as e:
#         logger.error(f"Failed to generate response: {e}")
#         raise
#
#
# # Example usage
# if __name__ == "__main__":
#     # Load the API token securely
#     api_token = os.getenv(langchainApiKey)
#     if not api_token:
#         logger.error("Environment variable LANGCHAIN_API_TOKEN is not set.")
#         raise EnvironmentError("API token is missing.")
#
#     # Initialize the LLM model
#     llm = initialize_llm_model(api_token=api_token)
#
#     # Simulate a query
#     query = "What are the top 5 features of the latest smartphone?"
#
#     # Get a response from the LLM
#     response = llm_interaction(query, llm)
#
#     # Print the response
#     print(response)
# Î©

import os
import logging
from typing import Optional
from pyChatGPT import ChatGPT

from rag_application.constants import langchainApiKey

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class LLMInteraction:
    @staticmethod
    def initialize_llm_model(model_name: str = 'gpt-chat', api_token: Optional[str] = None) -> ChatGPT:
        """
        Initializes the LLM model with LangChain.

        :param model_name: The name of the model to use ('gpt-chat' by default).
        :param api_token: The options API token for authentication.
        :return: An instance of the ChatGPT model.
        """
        if not api_token:
            logger.error("API token is required for initializing the LLM model.")
            raise ValueError("API token is required.")

        return ChatGPT(model_name=model_name, api_token=api_token)

    @staticmethod
    def llm_interaction(query: str, llm: ChatGPT) -> str:
        """
        Interacts with the LLM to generate a response based on the given query.

        :param query: The query to send to the LLM.
        :param llm: An instance of the ChatGPT model.
        :return: The response generated by the LLM.
        """
        try:
            response = llm.driver.send_message(query)
            logger.info(f"Received response: {response[:50]}...")
            return response
        except Exception as e:
            logger.error(f"Failed to generate response: {e}")
            raise

    if __name__ == "__main__":
        api_token = os.getenv(langchainApiKey)
        if not api_token:
            logger.error("Environment variable LANGCHAIN_API_TOKEN is not set.")
            raise EnvironmentError("API token is missing.")

        # Initialize the LLM model
        llm = initialize_llm_model(api_token=api_token)
